# snakemake                             # to run
# snakemake --force clear               # to force rule
# snakemake -n                          # check workflow
# REMEMBER REMEMBER : pipe in powershell wraps the object into utf-16 char set (avoid it...evil!)
# WIN32 :=  cmd /C "snakemake --dag | dot -Tpdf > workflow.pdf"
# UNIX  :=  snakemake --dag | dot -Tpdf > workflow.pdf

from __future__ import print_function
from __future__ import division


import os
import cv2
import tqdm
import shutil
import pickle
import operator
import numpy as np
import pandas as pd
from glob import glob
from PIL import Image
from openslide import OpenSlide
from numpy.fft import fft2 as fft
import xml.etree.ElementTree as ET
from sklearn.pipeline import make_pipeline, make_union
from sklearn.decomposition import PCA
from sklearn.model_selection import LeaveOneGroupOut
from sklearn.preprocessing import StandardScaler


configfile: 'config.yaml'

local = os.getcwd()
Image.MAX_IMAGE_PIXELS = 425980833600 # 100 times the default maximum size

svs_dir = os.path.abspath(config['SVS']['slide_dir'])
svs_ext = config['SVS']['extension']

xml_dir = os.path.abspath(config['XML']['xml_dir'])
xml_ext = config['XML']['extension']


patch_dir    = os.path.abspath(config['PATCH']['patch_dir'])
patch_size   = int(config['PATCH']['size'])
patch_stride = int(config['PATCH']['stride']) # overlap between patches
patch_svs    = '_'.join([patch_dir, config['SVS']['slide_dir']])
patch_ann    = '_'.join([patch_dir, config['XML']['xml_dir']])

interest_key   = config['INTEREST']['key']
interest_value = config['INTEREST']['value']

pca_train_perc = float(config['EIGENSLICES']['train_perc'])
pca_test_perc  = float(config['EIGENSLICES']['test_perc'])
pca_ncomp      = int(config['EIGENSLICES']['n_components'])

if pca_train_perc + pca_test_perc != 1.:
  raise ValueError('Train-Test percentages must be sum to 1 for Eigenslices! Given train:{} test:{}'.format(pca_train_perc, pca_test_perc))

nth_make_colormap        = config['NTH_CMAP']
nth_make_annotation      = config['NTH_ANNOTATION']
nth_make_patches         = config['NTH_PATCHES']
nth_make_patche_cnt      = config['NTH_PATCH_COUNTERS']
nth_merge_patch_counters = config['NTH_MERGE_PATCH_COUNTERS']
nth_extract_interest     = config['NTH_EXTRACT_INTEREST']


xmls = [os.path.splitext(os.path.basename(f))[0] for f in glob(os.path.join(xml_dir, '*.{}'.format(xml_ext)))]
svss = [os.path.splitext(os.path.basename(f))[0] for f in glob(os.path.join(svs_dir, '*.{}'.format(svs_ext)))]
ann_dir = os.path.join(os.path.dirname(svs_dir), 'annotation')

# consistency check
assert sorted(xmls) == sorted(svss)

os.makedirs(os.path.join(patch_svs), exist_ok=True)
os.makedirs(os.path.join(patch_ann), exist_ok=True)
os.makedirs(ann_dir,                 exist_ok=True)





rule all:
  input:
    patches_db = os.path.join(local, 'ann_db.dat'),





rule make_colormap:
  input:
    xml_filenames = expand(os.path.join(xml_dir, '{xml}.%s'%(xml_ext)), xml=xmls),
  output:
    color_map = os.path.join(local, 'cmap.dat'),
  benchmark:
    os.path.join('benchmark', 'benchmark_colormap.dat')
  threads:
    nth_make_colormap
  message:
    'Make global annotation colormap step'
  run:
    colors = set()

    for xml in input.xml_filenames:

      tree = ET.parse(xml)
      root = tree.getroot()

      colors.update((reg.get('color') for reg in root.iter('contour')))

    colors.add('#000000') # manually add black
    range_color = np.linspace(0, 255, len(colors)).astype(int)

    with open(output.color_map, 'w', encoding='utf-8') as out:
      # write header
      out.write('color,encoded\n')
      for i, c in zip(range_color, colors):
        out.write('{},{:d}\n'.format(c, i))







rule make_annotation:
  input:
    svs_filename = os.path.join(svs_dir, '{svs}.%s'%(svs_ext)),
    xml_filename = os.path.join(xml_dir, '{svs}.%s'%(xml_ext)),
    color_map    = os.path.join(local, 'cmap.dat'),
  output:
    svs_filename = os.path.join(ann_dir, 'roi_{svs}.png'),
    ann_filename = os.path.join(ann_dir, 'ann_{svs}.png'),
  benchmark:
    os.path.join('benchmark', 'benchmark_annotation_{svs}.dat')
  threads:
    nth_make_annotation
  message:
    'Make annotation step for {wildcards.svs}.%s'%(svs_ext)
  run:
    # load colormap
    with open(input.color_map, 'r', encoding='utf-8') as fp:
      rows = fp.read().splitlines()

    # check right fmt
    assert len(rows[0].split(',')) == 2

    cmap = {}
    for row in rows[1:]:
      color, encoded = row.split(',')
      cmap[color] = int(encoded)

    # Import full SVS large-image
    # osr = OpenSlide(input.svs_filename)
    osr = Image.open(input.svs_filename)

    # compute max dimension of the image
    # w, h = osr.level_dimensions[0] # max size
    w, h = osr.size

    mat = np.zeros(shape=(h, w), dtype='uint8')

    # Import xml file and get root
    tree = ET.parse(input.xml_filename)
    root = tree.getroot()

    whole_points = []

    # Find data in xml file
    for reg in root.iter('contour'):
      key = reg.get('name').upper()
      color_code = reg.get('color')

      points = [tuple(map(round, eval(vert.text))) for vert in reg.iter('point')]

      cnt = np.asarray(points).reshape((-1, 1, 2)).astype(np.int32)

      cv2.fillPoly(img=mat, pts=[cnt], color=cmap[color_code], lineType=8, shift=0)

      whole_points.extend(points)

    # extract ROI from annotated images
    minx = min(map(operator.itemgetter(0), whole_points))
    miny = min(map(operator.itemgetter(1), whole_points))
    maxx = max(map(operator.itemgetter(0), whole_points))
    maxy = max(map(operator.itemgetter(1), whole_points))

    # seeden viewer allows to create rois outside the image boundaries!!
    maxx = np.clip(maxx, 0, w)
    maxy = np.clip(maxy, 0, h)

    minx = np.clip(minx, 0, w)
    miny = np.clip(miny, 0, h)

    # extract the annotated ROI
    roi = mat[miny : maxy, minx : maxx]
    # evaluate paddding for the ROI according to the desired size
    w, h = roi.shape
    pad_w = max(patch_size - (w % patch_size), 0)
    pad_h = max(patch_size - (h % patch_size), 0)

    # Number of raws/columns to be added for every directons
    pad_top    = pad_w >> 1 # bit shift, integer division by two
    pad_bottom = pad_w - pad_top
    pad_left   = pad_h >> 1
    pad_right  = pad_h - pad_left

    # pad the annotated image
    padded = np.pad(roi, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=(0, 0))
    # save it
    cv2.imwrite(output.ann_filename, padded)

    # extract the corresponding ROI in the original image
    # mat = osr.read_region(location=(miny, minx), level=0, size=(maxy - miny, maxx - minx)).convert('RGB')
    roi_original = osr.crop(box=(minx, miny, maxx, maxy)).convert('RGB')
    # pad the original image
    padded = np.pad(roi_original, ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)), mode='constant', constant_values=(0, 0))
    # save it
    cv2.imwrite(output.svs_filename, padded)



rule make_patches:
  input:
    svs_filename = os.path.join(ann_dir, 'roi_{svs}.png'),
    ann_filename = os.path.join(ann_dir, 'ann_{svs}.png'),
    color_map    = os.path.join(local, 'cmap.dat'),
  output:
    # patches_svs = dynamic(os.path.join(patch_svs, '{svs}_{patch}.png')),
    # patches_ann = dynamic(os.path.join(patch_ann, '{svs}_{patch}.png')),
    patches_cnt = os.path.join(ann_dir, 'ann_{svs}_counter.dat'),
  benchmark:
    os.path.join('benchmark', 'benchmark_patch_{svs}.dat')
  threads:
    nth_make_patches
  message:
    'Make patches step for {wildcards.svs}.%s'%(svs_ext)
  run:
    filename = os.path.basename(input.svs_filename)
    name, ext = os.path.splitext(filename)

    # Import full SVS large-image
    osr = Image.open(input.svs_filename)
    osr = np.asarray(osr, dtype=np.uint8)
    # Import full Annotated large-image
    ann = Image.open(input.ann_filename)
    ann = np.asarray(ann, dtype=np.uint8)

    # take size of ONLY the first level
    width, height, _ = osr.shape

    # load colormap
    with open(input.color_map, 'r', encoding='utf-8') as fp:
      rows = fp.read().splitlines()

    # check right fmt
    assert len(rows[0].split(',')) == 2

    cmap = {}
    for row in rows[1:]:
      color, encoded = row.split(',')
      cmap[int(encoded)] = color

    # start to generate patches

    with open(output.patches_cnt, 'w', encoding='utf-8') as counter:
      # write header
      counter.write('Filename,{}\n'.format(','.join([v for _, v in cmap.items()])))

      for col in tqdm.tqdm(range(0, width, patch_size - patch_stride)):
        for row in tqdm.tqdm(range(0, height, patch_size - patch_stride)):

          svs_patch = osr[row : row + patch_size, col : col + patch_size]
          ann_patch = ann[row : row + patch_size, col : col + patch_size]

          unique_ann = set(ann_patch.ravel())

          # save only if there is a signal
          if all(v == 0 for v in unique_ann):
            continue

          outfile = '{}_{:d}_{:d}.png'.format(name, col, row)
          patches_svs = os.path.join(patch_svs, outfile)
          patches_ann = os.path.join(patch_ann, outfile)

          cv2.imwrite(patches_svs, svs_patch)
          cv2.imwrite(patches_ann, ann_patch)

          # save counter of labels
          # print on file the corresponding areas as boolean mask
          tags = ','.join([str(int(k in unique_ann)) for k, _ in cmap.items()])

          assert len(tags) == 7

          # write output
          counter.write('{},{}\n'.format(outfile, tags))




rule merge_patch_counters:
  input:
    patches_cnt = expand(os.path.join(ann_dir, 'ann_{svs}_counter.dat'), svs=svss),
  output:
    patches_db = os.path.join(local, 'ann_db.dat'),
  benchmark:
    os.path.join('benchmark', 'benchmark_db_patch.dat')
  threads:
    nth_merge_patch_counters
  message:
    'Make merge patch counters step'
  run:
    # concatenate all files into a single db

    # copy the first file just to include the header
    shutil.copyfile(input.patches_cnt[0], output.patches_db)

    # append all the other files without header
    for input_file in input.patches_cnt[1:]:
      with open(input_file, 'r', encoding='utf-8') as fp:
        rows = fp.read().splitlines()

      # append to the DB file
      with open(output.patches_db, 'a', encoding='utf-8') as out:
        for row in rows[1:]:
          out.write(row + '\n')


rule extract_interest:
  input:
    patches_db = os.path.join(local, 'ann_db.dat'),
  output:
    interest_db = os.path.join(local, 'only_{interest}_db.dat'.format(**{'interest' : interest_value})),
  benchmark:
    os.path.join('benchmark', 'benchmark_extract_interest.dat')
  threads:
    nth_extract_interest
  message:
    'Extracting interest portion of patches DB'
  run:

    patches_db = pd.read_csv(input.patches_db, sep=',', header=0)
    colors = set(patches_db.columns) - {'Filename'}

    if not interest_key in colors:
      raise ValueError('Interest key not found in the CMAP of patches db! Possible keys are {}'.format(', '.join(map(str, colors))))

    query = ' & '.join(("(patches_db['{}'] == 0)".format(k) for k in colors if k != interest_key))
    query = ' & '.join((query, "(patches_db['{}'] == 1)".format(interest_key)))

    extract = patches_db[eval(query)]

    extract.to_csv(output.interest_db, sep=',', header=True, index=False)


rule eigenslices:
  input:
    interest_db = os.path.join(local, 'only_{interest}_db.dat'.format(**{'interest' : interest_value})),
  output:
    pca_coords = os.path.join(local, 'pca_coords_ncomp{ncomp}_ntrain_{ntrain}.pickle'.format(**{'ncomp' : pca_ncomp, 'ntrain' : pca_train_perc})),
  benchmark:
    os.path.join('benchmark', 'benchmark_eigenslices.dat')
  threads:
    nth_extract_interest
  message:
    'Computing Eigenslices of interest subset'
  run:

    db = pd.read_csv(input.interest_db, sep=',', header=0)
    db['svs'] = db['Filename'].str.split('_').str[1]
    groups = np.asarray(db.svs, dtype=int)

    files = (os.path.join(patch_svs, f) for f in db.Filename)
    images = np.asarray([cv2.imread(f) for f in files])

    pipe = make_pipeline(StandardScaler(), PCA(n_components=pca_ncomp))
    logo = LeaveOneGroupOut()

    # TODO: split this loop along available workers (different rules)
    results = []
    for train_index, test_index in logo.split(X=images, groups=groups):
      X_train = images[train_index].reshape(len(train_index), -1)
      X_test  = images[test_index].reshape(len(test_index), -1)

      X_train = abs(fft(X_train))
      X_test  = abs(fft(X_test))

      pca_coords = pipe.fit(X_train).transform(X_test)
      results.append(pca_coords)

    results = np.concatenate(results)

    with open(output.pca_coords, 'wb') as fp:
      pickle.dump(results, fp, 2)

